\documentclass[12pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsfonts}
\usepackage{mitpress}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{csvsimple}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows}
\usetikzlibrary{positioning}

\newcommand{\bigCI}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp$}}}}

%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.50.0.2960}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=Manual}
%TCIDATA{Created=Wednesday, July 19, 2017 07:02:22}
%TCIDATA{LastRevised=Wednesday, July 19, 2017 07:41:44}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="DocumentShell" CONTENT="Articles\SW\A Simple MIT Press Article">}
%TCIDATA{CSTFile=40 LaTeX article.cst}

\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\newdimen\dummy
\dummy=\oddsidemargin
\addtolength{\dummy}{72pt}
\marginparwidth=.5\dummy
\marginparsep=.1\dummy

%\input{tcilatex}

\begin{document}

\title{A Suite of Bayesian Diagnostics for the Chain Event Graph}
\author{Rachel L. Wilkerson and Jim Q. Smith \\
%EndAName
University of Warwick and the Alan Turing Institute}
\maketitle

\begin{abstract}
The class of Chain Event Graphs has now been established as a practical
Bayesian graphical tool for modelling a variety of processes. However
although a number of techniques for estimating this and performing model
selection on this class have now been developed no bespoke methods of
diagnostically checking representatives within this family have been yet
developed. In this paper we rectify this situation and provide a number of
new Bayesian diagnostics that parallel those available for the more
restrictive class of Bayesian Network models. These are designed to check
the continued validity of the selected model as data about a population
continues to be collected. The efficacy of our methods are illustrated
through a simulation study and then the study of\ two well known CEG
studies: the first on a study of Childhood illness in the New Zealand and
the second on prison radicalization processes.      .
\end{abstract}

\section{Introduction }

Decision makers and stakeholders often need to know the structure in order to identify the most efficient interventions in the system. Bayesian networks are the primary tool used for structural elicitation \cite{Lord2016,Pitchforth2013}. The content, structure, and probabilitites of a BN may be obtained via elicitation, and protocols for this procedure have been outlined in \cite{EFSA} \cite{Ohagan}. 

The BN framework necessitates framing causal queries in terms of random variables. However, people describe causes as events rather than as configurations of sets of random variables. Coercing a narrative about a series of events to a BN is possible, and may indeed be helpful, but framing queries as a series of events is often more natural. 

%%CITE

%
%Yet, eliciting edges often obscures the meaning about what the links between edges means. To borrow Pearl's causal interpretation, the underlying notion of cause depends on encoding conditional probabilities depicted graphically by the absence of an edge between nodes. Structures elicited from experts rarely obey this rigid interpretation of cause.
%
%Participants are more likely to draw an arrow between events that have a link in a particular context, irrespective of a temporal ordering. The interpretation of these edges is obscured. For a BN, they may be read generally as an indication of which measurements affect others.
%
%In all but the most abstruse applications, causes happen before events. This may be obscured by the structure of BN. Often, additional context-specific information must be applied to the BN to create invariant temporal orderings.
%Yet, the BN formatting of complex problems does not respect temporal ordering, rendering ``causal'' arrows inconsistent. 


The causal hypotheses encoded by the BN may require settings of variables that do not faithfully represent the reality of what happens with a graph. As shown in \cite{SPIRTES}, to consider causes as settings of random variables rather than events using valid methods, the entire set of possible setting of each of the variables $x \in \mathbb{X}$ should be specified. But in practice, people do not stop to check that each of the possible configurations of variable settings is coherent as they tell their story! 


Causality has long been expressed in terms of event trees--a more suitable framework for elicited structures \cite{Shafer1996}.
Event trees are a finite tree $\mathcal{T} = (V(\mathcal{T}), E(\mathcal{T}))$ on a set of vertices and edges where the vertices are chance nodes and the edges of the tree label the possible events that can happen. A non-leaf vertex of a tree is called a situation and $S(\mathcal{T})$ denotes the set of situations. %CITE BARCLAY
On the path from the root vertex to a situation $s_i \in S(\mathcal{T})$ is a sequence of possible unfolding events.

Smith and Thwaites developed a new class of graphical model called chain event graphs building on the framework of probability trees. These express a much richer class of probabilities than that of the BN. %CITE. 
They extend the BN machinery to a different class of model in which the nodes are events rather than random variables.

This is a powerful model for participatory research, as participants often think in terms of a series of events rather than as a series of controlled measurements in a particular scenario. 

The aim of an expert elicitation session is to have a robust model that says something about the population we want to model
models holds for similar problems in different areas (in the case of the bracken for ex., in the crime example to have profiles of the series of events that leads to radicalization of people online, in the food poverty examples, we want to understand the narrative that leads to people having insufficient food.) 

\section{Chain Event Graphs, their meaning and estimation}

Let $T =( V(T),E(T))$ denote a directed tree with $V(T)$ and $E(T)$ denoting the node and edge set respectively. $L(T)$ represents the leaf nodes and $S(T) = \{s_1, \ldots, s_m\} =  \{v: v \in V(T) \setminus L(T)\}$ is the set of situation nodes. $\lambda (v,v')$ is the path from $v \in S(T)$ to $v \in V(T)$ and $\mathbb{X} = \Lambda(v_0,T) $ is the set of root to leaf paths where $v_0$ indicates the root node.  

The sample space $\mathbb{X}(v)$ is defined as the children of $v \in S(T)$. For an event tree, each situation $v \in S(T)$ has an associated random variable $X(V)$. Each situation in the event tree has sample space $\mathbb{X}(v)$. The distribution is governed by the primitive probabilities $\theta(v) = \{ \theta(v,v') = p(X(v)) = v' : v' \in \mathbb{X}(v)\}$. Because variables on the same path are conditionally independent, then $\theta(v,v')$ is an edge coloring. Thus we can define $\pi(e) = \theta(v,v')$.

A floret for a particular situation $v \in S(T)$ is a subtree $\mathcal{F} = (V(\mathcal{F}(v)), E(\mathcal{F}(v)))$ where the vertex set is the situation and its children, $V(\mathcal{F}(v)) = v \cup \mathbb{X}(v)$. The edge set $E(\mathcal{F}(v)) = \{ e \in E(T) \: e = (v,v') : v' \in \mathbb{X}(v) \}$. 

Two situations $v, v' \in S(T)$ are in the same stage if and only if the distributions of the situation are equivalent, that is $\psi_u(v,v') : \mathbb{X}(v) \to \mathbb{X}(v')$. This results in a set of stages of the tree denoted as $U(T)$. The set $S(T)$ itself is a trivial staging that adds no additional information about the tree. 

There is a finer partition of events using the notion of situations in the same position. Two situations $v, v' \in S(T)$ that are in the same stage are also in the same position $W(T)$ if and only if the subtrees $T(v)$ are equivalent to $T(v')$, and the probability distributions for each floret in the subtree are equivalent. That is, there is a bijection between $E(T(v))$ and $E(T(v'))$. 

Building on the concepts of stages and positions, a CEG may be constructed from a staged event tree by collapsing the nodes over the positions. Formally, a CEG $\mathcal{C} = V(\mathcal{C}), E(\mathcal{C})$ where $V(\mathcal{C}) = W(T) \cup w_\infty$, the staged tree positions plus the leaf nodes denoted $w_\infty$. 

%\{Review Ch 4, 5 ,6 and \& of book referenced back to sources. So the key
thing here to focus on is

%CEGs are composed of situations $v_1, \ldots, v_\infty$. It may be that for some set of situations in the event tree, the probability distribution among the florets is independent of the preceding events. In this case, we say those situations are in the same stage.  

The implications of a CEG models especially its stage structure which
is the analogue of the graphical conditional independence in the BN
\cite{Dawid 1979} \cite{Studen 2005} The stage structure. For a staged tree $T = V(T), E(T)$ and corresponding CEG, $\mathcal{C}$, a set of situations $W \subseteq V$, indicates a fine cut if the disjoint union of events equals the whole set of roof to leaf nodes. That is, no event in $W$ is upstream or downstream of another situation in the set and $\cup_{w \in W} \lambda(w) = \Lambda (T)$.

Similarly, a set of stages $W' \subseteq U(T)$ is a cut if and only if $\{ v \in u | u \in W'\} $ is a fine cut. $X_W$ is a cut variable if and only if  $W$ is a cut or a fine cut. The terminology of cuts admits an analogous conditional independence. 

Let $Y_{\prec W} = (Y_w | w \text{upstream of } W)$ and $ Y_{W\preceq} = (Y_{w'}  | w' \text{downstream of } W) $. Then the following conditional independence statements hold:  

\begin{itemize}
	\item if $W'$ is a fine cut then $Y_{\prec W'} \bigCI Y_{W'\preceq} \,|\, X_{W'}$ 
	\item if $W'$ is a cut then $Y_{\prec W'} \bigCI Y_{W'} \,|\, X_{W'}$ 
\end{itemize}

Thus, situations in the same stage are independent conditional on their respective histories. The proof of the above statements can be found in \cite{SmithAnderson} \cite{ThwaitesSmith}.


%There are many ways to graphically express conditional independence. In Bayesian networks, each variable is independent of its nondescendants given its parents. \cite{ Boutilier 1996} and \cite{GeigerandHeckerman1996} proposed ``context specific independence.''
  

 The conjugate analysis especially the implications for the one step
ahead predictive distributions. This has not been done yet explicitly but I
know how this works and is closely analogous to the BN predictives. This
would be one of the novelties of the paper \}

Check Freeman and Smith 2011.



\section{Model Diagnostics for Bayesian Networks}

\{Review of Cowell et al plus some others like Korb and Nicholson.\ Here we
need to check stage homogeneity - a sort of Bayesian hypothesis test on the
fact that data from the application really does have the same conditional
distributions where it says it does, Howeverr. I would place our main focus
here on the prequential methods on Dawid as discussed for BNs in Cowell.
These will link not only to predictives on the different stages but the
composite system as well\}

We want to check that the structure of our model is in line with observed data. A reliable model will be able to detect changes in parameters, be resilient to outlying observations, and make accurate forecasts for future observations\cite{Dawid1984}. The literature contains several methods for determining how well the data suits the model. 

One such measure in \cite{KORB} uses a metric called the conflict measure to detect incoherence in the data. Given some evidence $\bm{E}=\{E_i=e_1,\ldots,E_m=e_m\}$, then the conflict measure is $C(\bm{E})=\log(P(E_1=e_1),\ldots,P(E_m=e_m))$. If the conflict measure is positive, that means the existing evidence must be conflicting. If the conflict is due to flawed data, we can then trace the source of the discrepancy. Algorithms for evaluating the efficacy of decision trees are also featured in \cite{KORB}. Beginning with the nodes that only have children, the utility of the chance nodes is a product of the probability of the outgoing links. The algorithm also computes the expected utility of each decision nodes. Thus, we have a measure for evaluating decision trees which makes sequential decisions. 

BN parameters may be adapted using several different methodologies. Fractional updating performs Bayesian propogations to get the posterior distribution over the unobserved values \cite{Spiegelhalter and Lauritzen}. Another technique, fading uses the time decay factor to underweight old data relative to the new data \cite{JENSEN}. Methods to test the structural integrity of the models are fewer. \cite{JENSEN} proposes accumulating cases and running a discovery algorithm again to incrementally adapt the structure. \cite{KORB} suggests a technique called Causal Minimium message Length (CaMML) in which the probabilities of each link in the network is reported after sampling. By retaining the priors on the links and reusing them while sampling, the structure may be adapted. 

\cite{DAWID} developed prequential methods to determine which probabilities are a suitable model fit. Diagnostic methods outlined there use a transformation of distributions to determine if the expected values are in line with the distribution. They may also be used to determine if one distribution for an element of the graphical model is preferred over another or not.


%For a random varibale $\bm{X}$ with $n$ observations $\{x_1, \ldots, x_n\}$ and probability distribution $P$ with associated marginal likelihood 
%\[
%p(x_1,\ldots,x_n) = p(x_1)p(x_2 | x_1), p(x_n | \bm{x}^{n-1})
%\]
%
%Then, define a new variable $Y_i = F_i(x_i | \bm{x}^{i-1})$ where $F$ is invertible, then we can prove

For our purposes, mirroring the methodology in \cite{diagnostics} suffices. The prequential methods in \cite{diagnostics} can be adapted to CEGs to obtain the desired goals. Prequential refers to methods that enable us to identify how good are the predictions the graph makes sequentially. 

\subsection{Checking the CEG Structure}

Preliminary checks of the structure of the CEG include checking that the partial ordering of the data is consistent with the observed data. \textcolor{red}{We can import this method from the CEG book yes?} We then check stage and position homogenaity: that the situations in the same position agree with the observations. \textcolor{red}{Is this the same thing as checking stage consistency in Chapter 5? }


 
\subsection{Scoring rules}


Assessing the structure of a CEG first requires a scoring metric. Brier scores and logarithmic scores are two available scoring rules. 

Each stage $u$ has probability distribution:
\[
p(\pi_u) = \frac{\Gamma (\alpha_u)}{\prod_{k=1}^{r_u} \Gamma (\alpha_{uk})} \prod_{k=1}^{r_u} \pi_{uk} ^{\alpha_{uk}-1}
\]

Then suppose we observe several cases of observed events at each stage with $n_k$ representing the counts in each of the $k$ edges emanating from the stage. Then the  revised distribution for $\pi_{uk}$ is given by 

\[
p(\pi_u | d) \propto \prod_{k=1}^{r_u} \pi_{uk}^{n_{uk} +\alpha_{uk} -1}
\]

where $\alpha_u = \sum_{k=1}^{u_r} \alpha_{uk}$ and $n = \sum_{k=1}^{u_r} u_{uk}$ 
\[
p(d | \alpha_{u1}, \ldots, \alpha_{uk}) = \frac{\Gamma(\alpha_u)}{\prod_{k=1}^{u_r} \Gamma(\alpha_{uk})} \frac{\prod_{k=1}^{u_r}\Gamma(\alpha_{uk} + n_{uk})}{\Gamma(\alpha_u + n)}
\]

Thus, the scoring metric is 
\[
S_m = -\log \left(\frac{\Gamma(\alpha_u)}{\prod_{k=1}^{u_r} \Gamma(\alpha_{uk})} \frac{\prod_{k=1}^{u_r}\Gamma(\alpha_{uk} + n_{uk})}{\Gamma(\alpha_u + n)}\right)
\]

To assess whether the total observed penalty $S$ is an issue or not, we need to calibrate its value. The relative approach involves establish a reference prior (such as a Dirichlet) and scoring the two as follows.

\[
\exp(S^{\text{ref}} - S) = \frac{p(\text{all data } | \text{ expert's prior})}{p(\text{all data } | \text{ reference prior})}
\]


The absolute approach does not involve an alternative system $S^{\text{ref}}$. Instead, we test the null hypothesis that the observed events are occurring with the probabilities encoded in the CEG. To use the prequential methods, we have $1 \leq m \leq M$ cases. Each case $m$  incurs the random penalty with the following expectation and variance given the expectation and variance where $p_m$ is 

\begin{equation}
p_m= \frac{\Gamma(\alpha_u)}{\prod_{k=1}^{u_r} \Gamma(\alpha_{uk})} \frac{\prod_{k=1}^{u_r}\Gamma(\alpha_{uk} + n_{uk})}{\Gamma(\alpha_u + n)})
\end{equation}

\begin{equation}
E_m = \sum_{k=1}^{r_u}  \log (p_m)
\end{equation} 

\begin{equation}
V_m = \sum_{k=1}^{r_u} (p_m) \log^2 (p_m) - E_m^2
\end{equation}

This gives the following equation for the $Z_m$, the prequential monitor. 

\[
Z_m = \frac{\sum_{m=1}^{M} S_m - \sum_{m=1}^{M} E_m}{\sqrt{\sum_{m=1}^{M} V_m}}
\]

%Given the probability distributions above, the expression for the subsequent logarithmic scoring mechanism for $M$ subsequent cases of the particular situation $v$ is given by: 
%
%\begin{equation}
%S = -\log \prod_{m=1}^{M} \pi (v_m)
%\end{equation}
%
%Thus the overall score for an event tree $\mathcal{T}$ is 
%
%\begin{equation}
%-\log \prod_{m=1}^{M} p_m(v_m)
%\end{equation}

%If we have a dataset with series of observations $m_j \, 1 \leq j \leq M$ to verify our elicited model, then we can use the determine the probability of the next observation given past observations $p(w_i | \bm{w}^{i-1})$. This provides a framework for considering the cases at each stage and determining how accurate sequential predictions will be. 
%
%Thus, we can estimate the log score of case $i$ for stage $w_i$ as $S_i = -\log \pi(w_i)$. Then over a series of time ordered events from $1 \leq i \leq M$ the score is 
%\[
%S= -\log\prod_{i=1}^M \pi(w_i) =  -\log \prod_{i=1}^{M} \pi(w_i| \bm{w}^{i-1})
%\]
%

%\paragraph{Absolute monitors}
%Our null hypothesis it that the model is correct. Thus, events occur with probabilities stated by the system before we observe each situation $v_t$, and the expectation value and variance are given by the following equations: 
%
%\begin{equation}
%E_t = - \sum_{k=1}^K \pi_t(d_k) \log \pi_t(d_k) \qquad
%V_t = - \sum_{k=1}^K \pi_t(d_k) \log^2 \pi_t(d_k) - E_t^2
%\end{equation}
% 
%where $d_k$ for $1 \leq k \leq K$ represents the possible values at the situation $t$. 
%
%Using this we can assess the goodness of fit at each time point $1 \leq t \leq T$.


\subsection{Node monitors}

The unconditional and conditional node monitors outlined in \cite{ibid} are useful metrics for determining the relevance and accuracy of individual nodes. Conditional node monitors take the value of parent nodes into account, whereas their unconditional counterparts do not. 


%It is sometimes important to assess the impact of one of the parent events on one of hte
%The scoring metrics offer a means to assess the structural integrity of the elicited tree.
%
Parent-child monitors are presented in \cite{diagnostics} as the probability of a particular observation $X_k = x_k$ given the setting of its parents, $\rho$ in a general chain graph model as:
\begin{equation}
-\log p_m (x_k | X_{pa(k)}=\rho)
\end{equation}


For the CEG, rather than considering the probabilities of observations as we do in the BN, we consider instead the probabilities of arriving in each stage of the CEG. The unconditional stage monitor for stage $v$ is $-\log p_m(v)$ and the conditional stage monitor is given by $-\log p_m (v | pa(v)=\rho_v)$, where $\rho_v$ is the setting of the parents of $v$. 

The stage monitors have been implemented in R.


%The probability distribution for each root to leaf path $\lambda \in \Lambda$, is given by $ \pi (\lambda) = \prod_{j=0}^{n[\lambda]-1} \pi(v_{j+1, \lambda} | v_{j,\lambda})$
%\textcolor{red}{do we think of monitors in the sense of each of the individual events acting or the whole root to leaf node? }
\subsection{Batch monitors}

Batch monitors are invariant to the ordering of the data. For a particular stage, we can calculate the expected counts using the adjusted Pearsons $\chi^2$ statistic.   
For all cases of the data in a particular BN, the batch monitors considers the distribution of a child node given the setting of a parent. This metric provides a quick glance of how well the structure is performing.

The CEG batch node is taken at each cut of stages. For the possible pathways in a particular cut, the pearson chi squared statistic demonstrates how closely the data follows the structure of the CEG in each cut. 



%In order to assess how the score fits the system, establish a relative system with associated penalty. 
%
%\[
%\exp(S_{\text{ref}} - S) = \frac{p(\text{all data} \,|\, \text{experts prior})}{p(\text{all data} \,|\, \text{reference prior})}
%\]
%For our purposes, we take the reference prior to be the Dirichlet distribution $\mathcal
%{D}(\frac{1}{K}, \ldots ,\frac{1}{K})$
%
%Situation monitors offer a way of assessing if each situation contributes to poor structure or poor associated probabilities.
%Suppose in the event tree, all of the evidence in $\mathcal{E}(\mathcal{T})$ is propogated except that given by $s_i(j)$, then we can calculate the contribution  by
%
%\[
%- \log(\pi_{s_i})(s_i j \,|\, \mathcal{E}(\mathcal{T}) \backslash s_i)
%\]

\section{Simulations and Experiments}

Here simulations are not that useful - in a sense they are bound to work and
we can work things out in closed form. However the diagnostics on real data
sets can pick up deficiencies in the fit of a chosen CEG fitted to the data.
There are a number of these fitted in the book included two BNs which are
also CEGs - the results of the different diagnostics could be developed for
each of these. 

The idea would be to dicsuss possible deficiencies. We might
then run another example (Rodrigo has created another data set on Prison
radicalisation but we have some other possiblities- the Cerebal Palsy
example, an example concerning New Zealand tourism and also posibly a new
food study if we have the data for this? 


\subsection{CHDS}

The Christchurch dataset has been used in Barclay 2013, Cowell and Smith 2014, and Collazzo and Smith 2016 to illustrate the expressveness of CEGs. 

The Christchurch Health and Development Study (CHDS) was conducted at the University of Otango, New Zealand (Fergusson et al 1986). It encompassed a five year longitudinal study of several explanatory variables including: 
\begin{itemize}
	\item Family social background, a categorical variable differentiating between high and low levels according to educational, socio-economic, ethnic measures and information about the childrenâ€™s birth.
	\item Family economic status, a categorical variable distinguishing between high and
	low status with regard to standard of living.
	\item Family life events, a categorical variable signalising the existence of low (0 to 5 events), moderate (6 to 9 events) or high (10 or more events) number of stressful events faced by a family over the 5 years.
	\item the likelihood of childhood hospitalization (a binary variable). 
\end{itemize}

Several BN and CEG representations have been considered in CITE. For this example, we consider two CEGs shown below

%GRAPHS
\begin{figure}
	\includegraphics{cegA.png}
	\caption{CEG A}
\end{figure}

\begin{figure}
	\includegraphics{CEGb.png}
	\caption{CEG B}
\end{figure}

%BN NODE MONITORS
\begin{figure}
	\includegraphics[width=5in]{bnUncondNode.png}
	\caption{Unconditional node monitors for different priors in a BN}
\end{figure}

\begin{figure}
	\includegraphics[width=6in]{bnCondNode.png}
	\caption{Conditional node monitors for BN A, B, C, D}
\end{figure}

%CEG STAGE MONITORS
\begin{figure}
	\includegraphics[width=6in]{cegUncondStage.png}
	\caption{Unconditional Stage Monitor for a critical structure change in CEG A and B.}
\end{figure}


\begin{figure}
	\includegraphics[width=6in]{cegCondStage.png}
	\caption{Conditional Stage Monitor for a critical structure change in CEG A and B.}
\end{figure}

We then compute the batch monitors for the BNs shown above 
Events | Social=Low, Economic=Low
Events | Social=Low
Social | Economic = Low
Social | Events=Low
The batch monitor for cut $X_{\text{events}}$ is 938.90 in CEG A and 840.64 in CEG B. 



%The BN representation of this dataset can be seen in Figure \ref{fig:bn}. 
%
%\tikzstyle{block} = [rectangle, draw, text centered, minimum height=2em, node distance=2cm]
%\tikzstyle{plain} = [draw=none, fill=none, node distance=2cm]
%
%\begin{figure}[!h]
%	\centering
%	\begin{tikzpicture}\label{fig:bn}
%	
%	\node (s) [plain] {Social Background $s$};
%	\node (f) [plain, below=.5cm of s]{Family Life Events $f$};
%	\node (e) [plain,left=.5cm of f] {Economic Situation $e$};
%	\node (h) [plain,right=.5cm of f] {Hospital Admissions $h$};
%	
%	\draw[->, >=stealth] (s) -- (e);
%	\draw[->, >=stealth] (e) -- (f);
%	\draw[->, >=stealth] (f) -- (h);
%	\draw[->, >=stealth] (s) -- (h);
%	\end{tikzpicture}
%\end{figure}
%
%The number of counts in each pathway: 
%
%
%
%\begin{tabular}{l|l|l|l|l}%
%  Social &  Economics & Events & Admission & n% specify table head
% \csvreader[head to column names]{counts.csv}{}% use head of csv as column names
% {\\\hline\csvcolii&\csvcoliii&\csvcoliv&\csvcolv&\csvcolvi}% specify your coloumns here
% 
%\end{tabular}
%    
%
%\begin{figure}
%	\includegraphics{Rplot.png}
%\end{figure}

\end{document}
